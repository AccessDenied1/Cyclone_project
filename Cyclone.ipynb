{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cyclone",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AccessDenied1/Cyclone_project/blob/master/Cyclone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YngtcZuM-LAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ryi0ZfDlvyx",
        "colab_type": "code",
        "outputId": "b78fa7b6-daa6-4ad4-b22a-27811cda8966",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2f-jUBX3DEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
        "#!/usr/bin/env python -W ignore::DeprecationWarning"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3B_LZcfXogI",
        "colab_type": "code",
        "outputId": "d615a3e7-caad-4f24-f6a1-18cf91385ea9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/drive/My\\ Drive/Cyclone_project/rigid_body"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Cyclone_project/rigid_body\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-vIUmlLQlnff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "from PIL import Image as Im\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "image_dir = ['1.jpg' , '2.jpg' , '3.jpg' , '4.jpg']\n",
        "data=[]\n",
        "for i in image_dir:\n",
        "    img = cv2.imread(i)\n",
        "    img = cv2.resize(img , (400, 400))\n",
        "    data.append(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRoXiJ-X99F4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YbCnIdFK6ij",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "#plotting the rigid body motion ,four images\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.animation as an\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import time\n",
        "for i in data:\n",
        "    cv2_imshow(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35uGTh9DpH3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_data=[]\n",
        "img = data[0]\n",
        "rows = img.shape[0]\n",
        "cols = img.shape[1]\n",
        "img_center = (cols / 2, rows / 2)\n",
        "for i in range(0,90):\n",
        "    M = cv2.getRotationMatrix2D(img_center, i, 1)\n",
        "    rotated_image = cv2.warpAffine(img, M, (cols, rows), borderValue=(255,255,255))\n",
        "    img_data.append(rotated_image)\n",
        "    #cv2_imshow(rotated_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QndVkKk50pqA",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "images=[]\n",
        "for i in img_data:\n",
        "    images.append(np.array(i))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WvjcawXGF1D",
        "colab_type": "text"
      },
      "source": [
        "# Gunnar Farneback method  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ed9L7-9e6VgK",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "frame1 = images[0].copy()\n",
        "prvs= cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JSUKm0Nn9Ar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hsv = np.zeros_like(frame1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztdY8YzQoUbi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hsv[...,1] = 255\n",
        "#print(hsv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az5EuP1WpGP1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i=2\n",
        "while(i<20):\n",
        "    frame2 = images[i].copy()\n",
        "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
        "    #Getting the flow information by comparing the two consecutive images(1st and second) given above\n",
        "    flow = cv2.calcOpticalFlowFarneback(prvs,next,None,0.5,3,43,3,7,1.5,0) \n",
        "    #Gettint the magnitude and angle of the velocity vector\n",
        "    mag,ang = cv2.cartToPolar(flow[...,0],flow[...,1])\n",
        "    hsv[...,0] = ang*180 / np.pi/2\n",
        "    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
        "    k = cv2.waitKey(30) & 0xff\n",
        "    if k == 27:\n",
        "        break\n",
        "    prvs = next\n",
        "    i=i+2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTqNUnwk2iqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Getting velocity in x and y direction(list x_vel and y_vel)th \n",
        "x_vel = np.zeros((400,400) , dtype = float)\n",
        "y_vel = np.zeros((400,400) , dtype = float)\n",
        "for i in range(400):\n",
        "    for j in range(400):\n",
        "        a,b = flow[i][j]\n",
        "        x_vel[i][j] = a\n",
        "        y_vel[i][j] = b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD7eJvo0S4RZ",
        "colab_type": "code",
        "outputId": "4c679293-aeea-471d-b2af-6dae957afa1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(np.max(y_vel))\n",
        "print(np.max(x_vel))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7875387072563171\n",
            "0.6441136598587036\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpzNBop2rqol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x_pos = np.zeros((100,100))\n",
        "# y_pos = np.zeros((100,100))\n",
        "# for i in range(100):\n",
        "#     for j in range(100):\n",
        "#         x_pos[i][j] = i\n",
        "#         y_pos[i][j] = j"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BInuS6X08WM3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #plotting \n",
        "# fig, ax = plt.subplots(figsize=(20,20))\n",
        "# ax.axis([0,100,0,100])\n",
        "# #ax.tick_params(length = 1)\n",
        "# #ax.xaxis.set_ticks([1.,2.,3.,100.])\n",
        "# ax.quiver(x_pos,y_pos,x_vel,y_vel, scale=10)\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfWri3DpsVCn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# method-2\n",
        "import numpy as np\n",
        "from scipy import signal\n",
        "def optical_flow(I1g, I2g, window_size, tau=1e-2):\n",
        " \n",
        "    kernel_x = np.array([[-1., 1.], [-1., 1.]])\n",
        "    kernel_y = np.array([[-1., -1.], [1., 1.]])\n",
        "    kernel_t = np.array([[1., 1.], [1., 1.]])#*.25\n",
        "    w = int(window_size/2) # window_size is odd, all the pixels with offset in between [-w, w] are inside the window\n",
        "    I1g = I1g / 255. # normalize pixels\n",
        "    I2g = I2g / 255. # normalize pixels\n",
        "    # Implement Lucas Kanade\n",
        "    # for each point, calculate I_x, I_y, I_t\n",
        "    mode = 'same'\n",
        "    fx = signal.convolve2d(I1g, kernel_x, boundary='symm', mode=mode)\n",
        "    fy = signal.convolve2d(I1g, kernel_y, boundary='symm', mode=mode)\n",
        "    ft = signal.convolve2d(I2g, kernel_t, boundary='symm', mode=mode) + signal.convolve2d(I1g, -kernel_t, boundary='symm', mode=mode)\n",
        "    u = np.zeros(I1g.shape)\n",
        "    v = np.zeros(I1g.shape)\n",
        "    # within window window_size * window_size\n",
        "    #print(\"Type of w = \",type(w) , type(I1g.shape[0]-w))\n",
        "    for i in range(w, I1g.shape[0]-w):\n",
        "        for j in range(w, I1g.shape[1]-w):\n",
        "            Ix = fx[i-w:i+w+1, j-w:j+w+1].flatten()\n",
        "            Iy = fy[i-w:i+w+1, j-w:j+w+1].flatten()\n",
        "            It = ft[i-w:i+w+1, j-w:j+w+1].flatten()\n",
        "            b = np.reshape(It, (It.shape[0],1)) # get b here\n",
        "            A = np.vstack((Ix, Iy)).T # get A here\n",
        "\n",
        "            if np.min(abs(np.linalg.eigvals(np.matmul(A.T, A)))) >= tau:\n",
        "                nu = np.matmul(np.linalg.pinv(A), b) # get velocity here\n",
        "                u[i,j]=nu[0]\n",
        "                v[i,j]=nu[1]\n",
        "    return (u,v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLqgbTWUseg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fr1 = images[0].copy()\n",
        "# prvs= cv2.cvtColor(fr1, cv2.COLOR_BGR2GRAY)\n",
        "# fr2 = images[2].copy()\n",
        "# net = cv2.cvtColor(fr2, cv2.COLOR_BGR2GRAY)\n",
        "# (u,v) = optical_flow(prvs, net, 16, tau=1e-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK4vvfPVsjbY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# np.max(u)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZFAZ24bsxd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #plotting \n",
        "# fig, ax = plt.subplots(figsize=(20,20))\n",
        "# ax.axis([0,100,0,100])\n",
        "# plt.quiver(x_pos[:],y_pos[:],u[:],v[:],color=\"red\",angles=\"xy\",scale_units=\"xy\",scale=1,)\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgisxCElaVQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def encode(i,j):\n",
        "#     return i+(j*400)\n",
        "# def decode(num):\n",
        "#     i = num%400\n",
        "#     j = (num - i)/400\n",
        "#     return i,j"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHSkB7pUtDvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ref_img = np.zeros((400,400,2) , dtype=np.float32)\n",
        "# labels = np.zeros((5000,2))\n",
        "# #labels = []\n",
        "# Train_x = []\n",
        "# k=0\n",
        "# #Dataset Generation from Gunnar Farneback method\n",
        "# for i in tqdm(range(400)):\n",
        "#     for j in range(400):\n",
        "#         Ref_y = y_vel[(399-i) : (799-i) , (399-j) : (799-j)]\n",
        "#         Ref_x = x_vel[(399-i) : (799-i) , (399-j) : (799-j)]\n",
        "#         Ref_img[:,:,0] = Ref_x\n",
        "#         Ref_img[:,:,1] = Ref_y\n",
        "#         #Ref_img[:,:,2] = np.zeros((400,400))\n",
        "#         labels[k][0] = i/400.0\n",
        "#         labels[k][1] = j/400.0\n",
        "#         Train_x.append(Ref_img.copy())\n",
        "#         k=k+1\n",
        "#         if(k==5000):\n",
        "#             break\n",
        "#     if(k==5000):\n",
        "#         break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fMzXZj-owzy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# X_train, X_Valid, y_train, y_valid = train_test_split(Train_x, labels, test_size=0.10, random_state=42)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.10, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NBbF0NypzoW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"X_Valid = \",len(X_Valid),\", Y_valid = \",y_valid.shape)\n",
        "# print(\"X_Train = \",len(X_train),\", Y_train = \",y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAVdyu1IOcpY",
        "colab_type": "code",
        "outputId": "55c98c0b-54c1-437b-f3b9-b8a7bf2000fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "from keras.layers import Input,Conv2D,MaxPooling2D,Flatten,Dense\n",
        "from keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8Dt-mW4MhRJ",
        "colab_type": "code",
        "outputId": "ca425de2-92e8-478c-f5fd-544f50219274",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "inputs = Input(shape=(200,200,2))\n",
        "x = Conv2D(32,(3,3) ,padding = 'same' , activation='relu')(inputs)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Conv2D(64, (3, 3) , activation='relu')(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Conv2D(128, (3, 3) , activation='relu')(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128 , activation='relu')(x)\n",
        "out1 = Dense(2 , activation='linear')(x)\n",
        "model = Model(inputs = inputs, outputs = out1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RbKDG3u1jmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from keras.applications.resnet import ResNet50\n",
        "#from keras.layers import GlobalAveragePooling2D , Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkhS4-Gf0m_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#base_model = ResNet50(include_top=False, weights='imagenet', input_tensor=None, input_shape=(400,400,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsgRs-Cj2OUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x = base_model.output\n",
        "# x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "# x = Dense(1024, activation='relu')(x)\n",
        "# x= Dropout(0.2)(x)\n",
        "# x = Dense(256, activation='relu')(x)\n",
        "# x= Dropout(0.2)(x)\n",
        "# x = Dense(64, activation='relu')(x)\n",
        "# x= Dropout(0.2)(x)\n",
        "# x = Dense(16, activation='relu')(x)\n",
        "# x= Dropout(0.2)(x)\n",
        "# predictions = Dense(2, activation='softmax')(x)\n",
        "# model = Model(inputs=base_model.input, outputs=predictions)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqSpoQEV_6iP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import keras\n",
        "# adam = keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, amsgrad=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crP9xFpx6iSh",
        "colab_type": "code",
        "outputId": "66349130-ab75-44fd-a9f0-2233026ab51b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "source": [
        "model.compile(loss='mse',\n",
        "              optimizer='adam',\n",
        "              metrics=['mse','mae','accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 200, 200, 2)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 200, 200, 32)      608       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 100, 100, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 98, 98, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 49, 49, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 47, 47, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 23, 23, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 67712)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               8667264   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 8,760,482\n",
            "Trainable params: 8,760,482\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7pYy-Pb4MUc",
        "colab_type": "text"
      },
      "source": [
        "#Sanity Checking of model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5j1hQDr4Rzs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_Sanity_data = np.array(X_train[0:1000])\n",
        "# Y_Sanity_data = np.array(y_train[0:1000])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkyyOUH-4aVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sanity_data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lct0xfEG4eLC",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "# history = model.fit(x=np.array(X_train), y=y_train , verbose = 1 , epochs = 20 , shuffle = True,validation_data=(np.array(X_Valid),y_valid))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc03F3O-rVGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# h= model.evaluate(x=np.array(X_test),y=y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ34Ts-RBdb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxhpUSkOlwv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import gc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqro7I6GOYe-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_size = 140000\n",
        "valid_size = 16000\n",
        "test_size = 4000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8kDWikrQiCm",
        "colab_type": "text"
      },
      "source": [
        "Train : 0 ~ 140000<br/>\n",
        "Valid : 140000 ~ 156000<br/>\n",
        "Test : 156000 ~ 160000<br/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g5LWv2DH8Y8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_list = []\n",
        "for i in range(400):\n",
        "    for j in range(400):\n",
        "        index_list.append([i,j])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0TkHJeWkD6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Ref_img = np.zeros((200,200,2) , dtype=np.float32)\n",
        "labels = np.zeros((40000,2))\n",
        "Train_x = []\n",
        "k=0\n",
        "#Dataset Generation from Gunnar Farneback method\n",
        "for i in range(200):\n",
        "    for j in range(200):\n",
        "        Ref_y = y_vel[199-i : 399-i , 199-j : 399-j]\n",
        "        Ref_x = x_vel[199-i : 399-i , 199-j : 399-j]\n",
        "        Ref_img[:,:,0] = Ref_x\n",
        "        Ref_img[:,:,1] = Ref_y\n",
        "        #labels.append([i/400.0 , j/400.0])\n",
        "        #labels[k] = (encode(i,j)/159999.0)\n",
        "        labels[k][0] = i/200.0\n",
        "        labels[k][1] = j/200.0\n",
        "        Train_x.append(Ref_img.copy())\n",
        "        k=k+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aGgzycdIHy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def get_Chunk_Data(st,size):\n",
        "#     Ref_img = np.zeros((200,200,2) , dtype=np.float32)\n",
        "#     labels = np.zeros((size,2))\n",
        "#     Train_x = []\n",
        "#     k=0\n",
        "#     for i in range(st,size+st):\n",
        "#         a = index_list[i][0]\n",
        "#         b = index_list[i][1]\n",
        "#         Ref_y = y_vel[(199-a) : (399-a) , (199-b) : (399-b)]\n",
        "#         Ref_x = x_vel[(199-a) : (399-a) , (199-b) : (399-b)]\n",
        "#         Ref_img[:,:,0] = Ref_x\n",
        "#         Ref_img[:,:,1] = Ref_y\n",
        "#         labels[k][0] = i/200.0\n",
        "#         labels[k][1] = j/200.0\n",
        "#         Train_x.append(Ref_img.copy())\n",
        "#         k=k+1\n",
        "#     return Train_x,labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyNhVq4buDFC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #x_data = np.zeros((3200, 400, 400, 3), dtype = np.float32)\n",
        "# for ep in range(10):\n",
        "#     count = 0\n",
        "#     acc = 1\n",
        "#     loss = 1\n",
        "#     mean_absolute_error = 1\n",
        "#     mean_squared_error = 1\n",
        "#     val_acc = 1\n",
        "#     val_loss = 1\n",
        "#     val_mean_absolute_error = 1\n",
        "#     val_mean_squared_error = 1\n",
        "#     st_train = 0\n",
        "#     st_vd = 140000\n",
        "#     chunk_size = 4000\n",
        "#     train_size = 140000\n",
        "#     valid_size = 16000\n",
        "#     valid_chunk = 2000\n",
        "#     while(st_train<train_size):\n",
        "#         gc.collect()\n",
        "#         data,label = get_Chunk_Data(st_train,chunk_size)\n",
        "#         val_data ,labl  = get_Chunk_Data(st_vd , valid_chunk)\n",
        "#         x_data = np.array(data)\n",
        "#         y_label = label.copy()\n",
        "#         valid_data = np.array(val_data)\n",
        "#         valid_label = labl.copy()\n",
        "#         history = model.fit(x = x_data , y = y_label , verbose = 0 , epochs = 1 , shuffle = True , batch_size = 32 , validation_data = (valid_data,valid_label))\n",
        "#         time.sleep(5)\n",
        "#         gc.collect()\n",
        "#         acc = min(acc , history.history['acc'][0])\n",
        "#         loss = min(loss , history.history['loss'][0])\n",
        "#         mean_absolute_error = min(mean_absolute_error , history.history['mean_absolute_error'][0])\n",
        "#         mean_squared_error = min(mean_squared_error , history.history['mean_squared_error'][0])\n",
        "#         val_acc = min(val_acc , history.history['val_acc'][0])\n",
        "#         val_loss = min(val_loss , history.history['val_loss'][0])\n",
        "#         val_mean_absolute_error = min(val_mean_absolute_error , history.history['val_mean_absolute_error'][0])\n",
        "#         val_mean_squared_error = min(val_mean_squared_error , history.history['val_mean_squared_error'][0])\n",
        "#         count = count + 1\n",
        "#         print(\"count = \",count)\n",
        "#         st_train = st_train+((int)(chunk_size/2))\n",
        "#         st_vd = st_vd + ((int)(valid_chunk/2))\n",
        "#         if(st_vd >= 156000):\n",
        "#             st_vd = 140000\n",
        "#         gc.collect()\n",
        "#     print (\"-----Epoch {}---------\".format(ep+1))\n",
        "#     print(\"------Minimum acc is {}------\".format(acc))\n",
        "#     print(\"------Minimum loss is {}------\".format(loss))\n",
        "#     print(\"------Minimum mean_absolute_error is {}------\".format(mean_absolute_error))\n",
        "#     print(\"------Minimum mean_squared_error is {}------\".format(mean_squared_error))\n",
        "#     print(\"------Minimum val_acc is {}------\".format(val_acc))\n",
        "#     print(\"------Minimum val_loss is {}------\".format(val_loss))\n",
        "#     print(\"------Minimum val_mean_absolute_error is {}------\".format(val_mean_absolute_error))\n",
        "#     print(\"------Minimum val_mean_squared_error is {}------\".format(val_mean_squared_error))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV5P0esrmK4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_Valid, y_train, y_valid = train_test_split(Train_x, labels, test_size=0.10, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.10, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFWXQVAOmX9D",
        "colab_type": "code",
        "outputId": "168d089d-a9d0-44a3-8f0e-44fdca001f60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"X_Valid = \",len(X_Valid),\", Y_valid = \",y_valid.shape)\n",
        "print(\"X_Train = \",len(X_train),\", Y_train = \",y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_Valid =  4000 , Y_valid =  (4000, 2)\n",
            "X_Train =  32400 , Y_train =  (32400, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Avt68GmmuVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.array(X_train[:])\n",
        "y_train = np.array(y_train[:])\n",
        "X_Valid = np.array(X_Valid[:])\n",
        "y_valid = np.array(y_valid[:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkh5W0LnnzeU",
        "colab_type": "code",
        "outputId": "0d9dadbd-4838-49bf-e4ef-4b28626be270",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import gc\n",
        "import time\n",
        "time.sleep(5)\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "168"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2nvq69YtBZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del Train_x\n",
        "del labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0Hush22mca9",
        "colab_type": "code",
        "outputId": "1c634285-de86-4ee0-bcce-4a45824f653f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "model.fit(x=X_train , y = y_train , verbose=1,epochs=10,shuffle=True , batch_size = 32,validation_data=(X_Valid,y_valid))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 32400 samples, validate on 4000 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "32400/32400 [==============================] - 42s 1ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - mean_absolute_error: 0.0177 - acc: 0.9764 - val_loss: 6.2847e-05 - val_mean_squared_error: 6.2847e-05 - val_mean_absolute_error: 0.0066 - val_acc: 0.9848\n",
            "Epoch 2/10\n",
            "32400/32400 [==============================] - 32s 991us/step - loss: 3.2036e-04 - mean_squared_error: 3.2036e-04 - mean_absolute_error: 0.0108 - acc: 0.9862 - val_loss: 9.6717e-05 - val_mean_squared_error: 9.6717e-05 - val_mean_absolute_error: 0.0070 - val_acc: 0.9910\n",
            "Epoch 3/10\n",
            "32400/32400 [==============================] - 32s 983us/step - loss: 5.3613e-05 - mean_squared_error: 5.3613e-05 - mean_absolute_error: 0.0052 - acc: 0.9946 - val_loss: 3.1027e-05 - val_mean_squared_error: 3.1027e-05 - val_mean_absolute_error: 0.0043 - val_acc: 0.9930\n",
            "Epoch 4/10\n",
            "32400/32400 [==============================] - 32s 989us/step - loss: 1.6399e-04 - mean_squared_error: 1.6399e-04 - mean_absolute_error: 0.0083 - acc: 0.9906 - val_loss: 9.0382e-06 - val_mean_squared_error: 9.0382e-06 - val_mean_absolute_error: 0.0023 - val_acc: 0.9960\n",
            "Epoch 5/10\n",
            "32400/32400 [==============================] - 31s 954us/step - loss: 4.6168e-05 - mean_squared_error: 4.6168e-05 - mean_absolute_error: 0.0048 - acc: 0.9943 - val_loss: 1.3616e-05 - val_mean_squared_error: 1.3616e-05 - val_mean_absolute_error: 0.0025 - val_acc: 0.9960\n",
            "Epoch 6/10\n",
            "32400/32400 [==============================] - 31s 954us/step - loss: 8.3455e-05 - mean_squared_error: 8.3455e-05 - mean_absolute_error: 0.0063 - acc: 0.9935 - val_loss: 9.5251e-06 - val_mean_squared_error: 9.5251e-06 - val_mean_absolute_error: 0.0024 - val_acc: 0.9950\n",
            "Epoch 7/10\n",
            "32400/32400 [==============================] - 31s 957us/step - loss: 7.7780e-04 - mean_squared_error: 7.7780e-04 - mean_absolute_error: 0.0101 - acc: 0.9872 - val_loss: 7.9224e-05 - val_mean_squared_error: 7.9224e-05 - val_mean_absolute_error: 0.0064 - val_acc: 0.9920\n",
            "Epoch 8/10\n",
            "32400/32400 [==============================] - 31s 954us/step - loss: 2.1207e-05 - mean_squared_error: 2.1207e-05 - mean_absolute_error: 0.0033 - acc: 0.9956 - val_loss: 1.1327e-05 - val_mean_squared_error: 1.1327e-05 - val_mean_absolute_error: 0.0026 - val_acc: 0.9950\n",
            "Epoch 9/10\n",
            "32400/32400 [==============================] - 31s 952us/step - loss: 2.0766e-05 - mean_squared_error: 2.0766e-05 - mean_absolute_error: 0.0034 - acc: 0.9952 - val_loss: 2.2568e-05 - val_mean_squared_error: 2.2568e-05 - val_mean_absolute_error: 0.0037 - val_acc: 0.9970\n",
            "Epoch 10/10\n",
            "32400/32400 [==============================] - 31s 951us/step - loss: 5.0456e-05 - mean_squared_error: 5.0456e-05 - mean_absolute_error: 0.0051 - acc: 0.9931 - val_loss: 8.0918e-05 - val_mean_squared_error: 8.0918e-05 - val_mean_absolute_error: 0.0069 - val_acc: 0.9920\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8c404ed048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irYx_Izhthzb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('200x200_10_epoch.model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_IS7g_f06S2",
        "colab_type": "code",
        "outputId": "60319b3d-e26e-4e7e-d023-12a3df6d7c12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "model.evaluate(x = np.array(X_test),y=y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3600/3600 [==============================] - 1s 366us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7.96196563816112e-05,\n",
              " 7.96196563816112e-05,\n",
              " 0.0069363723446925485,\n",
              " 0.9958333333333333]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4wzxN5i2uZc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}